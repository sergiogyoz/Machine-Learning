{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW recap and setup\n",
    "\n",
    "We will train Random Forest classifier and Gradient Boosting classifier for MNIST.\n",
    "\n",
    "Use the seed 0 everywhere.\n",
    "\n",
    "1. Import MNIST data as we did in Lecture 7. We are only going to use digit 0 and digit 1. So extract only those examples and discard the rest.\n",
    "\n",
    "Next, randomly split the data into 80% training data and 20% testing data. Then split the training data again into 75% training data and 25% validation data. Keep this split fixed throughout the experiments.\n",
    "\n",
    "2. Use the validation set to choose the optimal hyperparameters \"n_estimators\" and \"max_depth\" for Random Forest, and report the best hyperparameters and the best validation error. The suggested hyperparameter values are\n",
    "\n",
    "    - ns_estimators = [10,20,50,100,200]\n",
    "    - max_depths = [1,2,5,10,20]\n",
    "\n",
    "3. Train Random Forest again with all data (i.e., training + validation data). Report the training and the test error.\n",
    "\n",
    "4. Plot the feature importance as an image, as we did in Lecture 7.\n",
    "\n",
    "5. Repeat 2 with Gradient Boosting.\n",
    "\n",
    "6. Repeat 3 with Gradient Boosting\n",
    "\n",
    "7. Repeat 4 with Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data = load_digits()\n",
    "X = data[\"data\"]\n",
    "Y = data[\"target\"] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Plot the first 100 images (with 10 images per row) as you did with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I'm stealing the code from class to plot and changing the size to make it work with the digits data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 8\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1 \n",
    "\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    padded_instances = np.concatenate([instances, np.zeros((n_empty, size * size))], axis=0)\n",
    "\n",
    "    image_grid = padded_instances.reshape((n_rows, images_per_row, size, size))\n",
    "\n",
    "    big_image = image_grid.transpose(0, 2, 1, 3).reshape(n_rows * size,\n",
    "                                                         images_per_row * size)\n",
    "    plt.imshow(big_image, cmap = mpl.cm.binary, **options)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plot_digits(X[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Randomly split the data into 80% training data and 20% testing data. Keep this split fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use pretty much the same procedure I used on the previous HW, create a permutation and then take the first 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(Y)\n",
    "np.random.seed(0)\n",
    "\n",
    "# create a random index permutation\n",
    "ind =np.array(range(0,m))\n",
    "ind = np.random.permutation(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n",
      "[2 8 2 ... 5 2 8]\n"
     ]
    }
   ],
   "source": [
    "# first 80% for train and last 20% for test \n",
    "split = int(m*0.8)\n",
    "train_ind = ind[0:split]\n",
    "test_ind = ind[split:m]\n",
    "\n",
    "print(Y)\n",
    "print(Y[train_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For each value of Cs = [1E-5,1E-4,1E-3,1E-2,1E-1,1E0]\n",
    "\n",
    "#### (a) instantiate LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "import warnings # to catch warnings\n",
    "\n",
    "\n",
    "C=[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0]\n",
    "cv=[]\n",
    "\n",
    "with warnings.catch_warnings():  # to remove convergence warning output\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    # for each c value fit to the train data and save the 4-cross validation scores\n",
    "    for c in C:\n",
    "        reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", penalty=\"l2\", C=c, random_state=0, max_iter=1000)\n",
    "        cv.append( cross_val_score(reg, X[train_ind], Y[train_ind], cv =4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) measure 4-fold cross_validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86388889 0.86629526 0.87743733 0.86908078]\n",
      "[0.91944444 0.90250696 0.91922006 0.9275766 ]\n",
      "[0.94444444 0.94428969 0.96100279 0.95264624]\n",
      "[0.95833333 0.96100279 0.9637883  0.9637883 ]\n",
      "[0.96111111 0.95821727 0.95821727 0.9637883 ]\n",
      "[0.96388889 0.95543175 0.94428969 0.95821727]\n",
      "mean cv values\n",
      "[0.8691755648406065, 0.9171870164035902, 0.9505957907768492, 0.9617281801299907, 0.9603334880841844, 0.9554569018879604]\n",
      "max cv  0.9617281801299907  at  0.01\n"
     ]
    }
   ],
   "source": [
    "# To compare we find the mean of each 4-cross validation's scores\n",
    "cvmean = []\n",
    "for i in range(6):\n",
    "    print(cv[i])\n",
    "    cvmean.append(np.average(cv[i]))\n",
    "print(\"mean cv values\")\n",
    "print(cvmean)\n",
    "\n",
    "# The better model corresponds to the higher score\n",
    "maxcv = np.max(cvmean)\n",
    "max = np.argmax(cvmean)\n",
    "print(\"max cv \", maxcv, \" at \", C[max])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Now use the hyperparameter to retrain the model from scratch using all training data. Report the train and test error of this final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use $C=0.01$ since this value yield better mean cross validation score, to find the train and test scores (notice we will be using the `score` method as the error, which corresponds to the cross validation error calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9902574808629089\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# fit to the train data\n",
    "reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", penalty=\"l2\", C=C[max], random_state=0, max_iter=1000)\n",
    "reg.fit(X=X[train_ind],y=Y[train_ind])\n",
    "\n",
    "# train error\n",
    "train_error = reg.score(X[train_ind],Y[train_ind])\n",
    "print(train_error)\n",
    "\n",
    "# test error\n",
    "test_error = reg.score(X[test_ind],Y[test_ind])\n",
    "print(test_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, the training score is $99.02\\%$ (or $0.98\\%$ error) and the test score is $97.77\\%$ (or $2.23\\%$ error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Repeat 3 with LogisticRegression(..., penalty=\"l1\", C=C, random_state=0, max_iter=1000, solver='saga')\n",
    "Now lets rinse and repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "import warnings # to catch warnings\n",
    "\n",
    "\n",
    "C=[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0]\n",
    "cv=[]\n",
    "\n",
    "with warnings.catch_warnings():  # to remove convergence warning output\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    # for each c value fit to the train data and save the 4-cross validation scores\n",
    "    for c in C:\n",
    "        # new regressor\n",
    "        reg = LogisticRegression(multi_class=\"multinomial\",solver=\"saga\", penalty=\"l1\", C=c, random_state=0, max_iter=1000)\n",
    "        cv.append( cross_val_score(reg, X[train_ind], Y[train_ind], cv =4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1        0.10306407 0.10306407 0.10306407]\n",
      "[0.1        0.10306407 0.10306407 0.10584958]\n",
      "[0.22222222 0.23119777 0.15877437 0.16155989]\n",
      "[0.91388889 0.91086351 0.93314763 0.92200557]\n",
      "[0.95       0.95821727 0.95543175 0.96657382]\n",
      "[0.96111111 0.9637883  0.95543175 0.96100279]\n",
      "mean cv values\n",
      "[0.10229805013927576, 0.10299442896935933, 0.1934385639121015, 0.9199764004952027, 0.9575557103064066, 0.9603334880841845]\n",
      "max cv  0.9603334880841845  at  1.0\n"
     ]
    }
   ],
   "source": [
    "# Find the mean of each 4-cross validation's scores\n",
    "cvmean = []\n",
    "for i in range(6):\n",
    "    print(cv[i])\n",
    "    cvmean.append(np.average(cv[i]))\n",
    "print(\"mean cv values\")\n",
    "print(cvmean)\n",
    "\n",
    "# The better model corresponds to the higher score\n",
    "maxcv = np.max(cvmean)\n",
    "max = np.argmax(cvmean)\n",
    "print(\"max cv \", maxcv, \" at \", C[max])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Repeat 4 with LogisticRegression(..., penalty=\"l1\", C=C, random_state=0, max_iter=1000, solver='saga')\n",
    "The first scores for this one really suck, the best result happens when $C=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9694444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paquito\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# fit to the train data\n",
    "reg = LogisticRegression(multi_class=\"multinomial\",solver=\"saga\", penalty=\"l1\", C=C[max], random_state=0, max_iter=1000)\n",
    "reg.fit(X=X[train_ind],y=Y[train_ind])\n",
    "\n",
    "# train error\n",
    "train_error = reg.score(X[train_ind],Y[train_ind])\n",
    "print(train_error)\n",
    "\n",
    "# test error\n",
    "test_error = reg.score(X[test_ind],Y[test_ind])\n",
    "print(test_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which yields a $100\\%$ train score (or $0\\%$ error) and a $96.94\\%$ test score (or $3.06\\%$ error) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2c347be7a09c79bec3584906b56bc46bcac2758b6dee90f1bb02256e0ead907"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
